{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Prepares the babi-memnn network.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import itertools\n",
    "from keras.models import *\n",
    "import random\n",
    "import sys\n",
    "from glob import glob\n",
    "import re\n",
    "from utils import *\n",
    "import tqdm\n",
    "import os\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "np.set_printoptions(precision=4, threshold=20)\n",
    "cfg = K.tf.ConfigProto(gpu_options={'allow_growth': True})\n",
    "K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "    def __init__(self):\n",
    "        self.word_idx_dict = {}\n",
    "        self.uniq_word_cnt = 0\n",
    "    \n",
    "    def update_vocab(self, tokens):\n",
    "        for word in tokens:\n",
    "            if word not in self.word_idx_dict:\n",
    "                self.word_idx_dict[word] = self.uniq_word_cnt\n",
    "                self.uniq_word_cnt += 1\n",
    "\n",
    "    def words_idx(self, tokens):\n",
    "        return [self.word_idx_dict[token] for token in tokens]\n",
    "    \n",
    "    def tokenize(self, sent):\n",
    "        return [x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]\n",
    "\n",
    "    \n",
    "class Examples:\n",
    "    \n",
    "    def __init__(self, c):\n",
    "        self.data = []\n",
    "        self.c = c\n",
    "        \n",
    "    def add(self, example_lines):\n",
    "        memories = []\n",
    "        memories_txt = []\n",
    "        qa = []\n",
    "        for eg_line in example_lines:\n",
    "            if \"\\t\" not in eg_line: #normal memory\n",
    "                eg_line = c.tokenize(eg_line)\n",
    "                c.update_vocab(eg_line)\n",
    "                mem_id, memory = eg_line[0], c.words_idx(eg_line[1:])\n",
    "                memories.append(c.words_idx(eg_line))\n",
    "                memories_txt.append(eg_line)\n",
    "            else: #question line\n",
    "                ques, ans, hints = eg_line.split(\"\\t\")\n",
    "                ques = c.tokenize(ques)[1:]\n",
    "                c.update_vocab(ques)\n",
    "                ans = c.tokenize(ans)\n",
    "                c.update_vocab(ans)\n",
    "                self.data.append(([m for m in memories],\n",
    "                                  c.words_idx(ques), c.words_idx(ans), [m for m in memories_txt]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import *\n",
    "def get_dataset_from_stories(examples, max_memory_len, max_num_memories, max_ques_len, vocab_size):\n",
    "    m, q, a = [], [], []\n",
    "    for (memories, ques, ans, v) in examples:\n",
    "        memories= pad_sequences(memories, maxlen=max_memory_len)\n",
    "        memories = np.concatenate([memories, np.zeros((max_num_memories - memories.shape[0],\n",
    "                                                       max_memory_len), 'int') ])\n",
    "        m.append(memories)\n",
    "        q.append(ques)\n",
    "        ans_vec = np.zeros((vocab_size))\n",
    "        ans_vec[ans] = 1\n",
    "        a.append(ans_vec)\n",
    "    return np.array(m), pad_sequences(q, maxlen=max_ques_len), np.array(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training files\n",
      "Reading data/tasks_1-20_v1-2/en-10k//qa2_two-supporting-facts_train.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amadaan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\re.py:203: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test files\n",
      "Reading data/tasks_1-20_v1-2/en-10k//qa2_two-supporting-facts_test.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 1000, 123, 88)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"data/tasks_1-20_v1-2/en-10k/\"\n",
    "\n",
    "c = Corpus()\n",
    "word_id = {}\n",
    "train_files = glob(data + \"/qa2_two-supporting-facts_train.txt\")\n",
    "test_files = glob(data + \"/qa2_two-supporting-facts_test.txt\")\n",
    "#train_files = glob(data + \"/qa1_single-supporting-fact_train.txt\")\n",
    "#test_files = glob(data + \"/qa1_single-supporting-fact_test.txt\")\n",
    "\n",
    "word_idx = {}\n",
    "uniq_word_cnt = 0\n",
    "\n",
    "\"Processing train files\"\n",
    "def process_files(file_paths, c):\n",
    "    examples = Examples(c)\n",
    "    for file_path in file_paths:\n",
    "        print(\"Reading {0}\".format(file_path))\n",
    "        with open(file_path, \"r\") as f:\n",
    "            eg_lines = [next(f).strip()]\n",
    "            for line in f:\n",
    "                if int(line.split(\" \", 1)[0]) == 1: #new story starts\n",
    "                    examples.add(eg_lines)\n",
    "                    eg_lines = [line.strip()]\n",
    "                else:\n",
    "                    eg_lines.append(line.strip())\n",
    "            if len(eg_lines) > 0:\n",
    "                examples.add(eg_lines)\n",
    "    return examples.data\n",
    "\n",
    "print(\"Processing training files\")\n",
    "train_examples = process_files(train_files, c)\n",
    "print(\"Processing test files\")\n",
    "test_examples = process_files(test_files, c)\n",
    "all_examples = train_examples + test_examples\n",
    "max_num_memories = max([len(memories[0]) for memories in all_examples])\n",
    "len(train_examples), len(test_examples), c.uniq_word_cnt, max_num_memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0, 32, 44, 3, 4, 27, 6],\n",
       "  [7, 8, 58, 4, 36, 14, 6],\n",
       "  [11, 8, 40, 41, 4, 42, 14, 6],\n",
       "  [15, 16, 17, 3, 4, 22, 6],\n",
       "  [19, 16, 17, 20, 3, 4, 10, 6],\n",
       "  [21, 1, 9, 3, 4, 30, 6],\n",
       "  [57, 8, 17, 3, 4, 27, 6],\n",
       "  [26, 8, 60, 4, 36, 14, 6]],\n",
       " [23, 24, 4, 36, 25],\n",
       " [27],\n",
       " [['1', 'Daniel', 'travelled', 'to', 'the', 'office', '.'],\n",
       "  ['2', 'Sandra', 'grabbed', 'the', 'milk', 'there', '.'],\n",
       "  ['3', 'Sandra', 'picked', 'up', 'the', 'apple', 'there', '.'],\n",
       "  ['4', 'John', 'went', 'to', 'the', 'garden', '.'],\n",
       "  ['5', 'John', 'went', 'back', 'to', 'the', 'bedroom', '.'],\n",
       "  ['6', 'Mary', 'journeyed', 'to', 'the', 'hallway', '.'],\n",
       "  ['7', 'Sandra', 'went', 'to', 'the', 'office', '.'],\n",
       "  ['8', 'Sandra', 'discarded', 'the', 'milk', 'there', '.']])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples[1400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min([len(m[3]) for m in all_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1000, 123, 88, 8, 5)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_num_memories = max([len(example[0]) for example in all_examples])\n",
    "max_memory_len = max([len(memory) for example in all_examples for memory in example[0]])\n",
    "max_ques_len = max([len(example[1]) for example in all_examples])\n",
    "vocab_size = c.uniq_word_cnt\n",
    "len(train_examples), len(test_examples), c.uniq_word_cnt, max_num_memories, max_memory_len, max_ques_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_train, q_train, a_train = get_dataset_from_stories(train_examples,\n",
    "                                                     max_memory_len,\n",
    "                                                     max_num_memories,\n",
    "                                                     max_ques_len,\n",
    "                                                     vocab_size=c.uniq_word_cnt)\n",
    "\n",
    "m_test, q_test, a_test = get_dataset_from_stories(test_examples,\n",
    "                                                     max_memory_len,\n",
    "                                                     max_num_memories,\n",
    "                                                     max_ques_len,\n",
    "                                                     vocab_size=c.uniq_word_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  1, ..., 36, 14,  6],\n",
       "       [ 0,  7, 16, ...,  4, 10,  6],\n",
       "       [11,  8, 17, ...,  4, 18,  6],\n",
       "       ..., \n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 88, 8)\n",
      "(10000, 5)\n",
      "(10000, 123)\n",
      "(1000, 88, 8)\n",
      "(1000, 5)\n",
      "(1000, 123)\n"
     ]
    }
   ],
   "source": [
    "print(m_train.shape)\n",
    "print(q_train.shape)\n",
    "print(a_train.shape)\n",
    "print(m_test.shape)\n",
    "print(q_test.shape)\n",
    "print(a_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  1, ...,  4,  5,  6],\n",
       "       [ 0,  7,  8, ...,  4, 10,  6],\n",
       "       [ 0, 11,  1, ..., 13, 14,  6],\n",
       "       ..., \n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_train[3] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### m_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(None), Dimension(88), Dimension(8)]),\n",
       " TensorShape([Dimension(None), Dimension(88), Dimension(30)]))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_in = Input(shape=(max_num_memories, max_memory_len))\n",
    "x = TimeDistributed(Embedding(input_dim=vocab_size, output_dim=n_hidden))(mem_in)\n",
    "m_i = Lambda(lambda xx: K.sum(xx, 2))(x)\n",
    "mem_in.shape, m_i.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 5, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(None), Dimension(5)]),\n",
       " TensorShape([Dimension(None), Dimension(1), Dimension(30)]))"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_input = Input(shape=(max_ques_len,))\n",
    "#u = Reshape(target_shape=(1, max_ques_len))(query_input)\n",
    "#u = TimeDistributed(Embedding(input_dim=vocab_size, output_dim=n_hidden))(u)\n",
    "u = Embedding(input_dim=vocab_size, output_dim=n_hidden)(query_input)\n",
    "print(u.shape)\n",
    "u = Lambda(lambda x : K.sum(x, 1))(u)\n",
    "u = Reshape(target_shape=(1, n_hidden))(u)\n",
    "#u = Lambda(lambda x : K.sum(x, 2))(u)\n",
    "query_input.shape, u.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 88)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(88), Dimension(1)])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = dot([m_i, u], axes=2)\n",
    "p = Reshape((max_num_memories,))(p)\n",
    "print(p.shape)\n",
    "p = Activation(activation='softmax')(p)\n",
    "p = Reshape((max_num_memories,1))(p)\n",
    "#p = Lambda(lambda x: K.tile(x, [1, 1, 100]))(p)\n",
    "p.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(88), Dimension(30)])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = TimeDistributed(Embedding(vocab_size, n_hidden))(mem_in)\n",
    "c_i = Lambda(lambda xx: K.sum(xx, 2))(x)\n",
    "c_i.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'reshape_191/Reshape:0' shape=(?, 1, 30) dtype=float32>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#o = multiply([c_i, p])\n",
    "o = dot([c_i, p], axes=1)\n",
    "o = Reshape(target_shape=(1,n_hidden))(o)\n",
    "#o = Lambda(lambda oo: K.sum(oo, 1))(o)\n",
    "o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_25/Softmax:0' shape=(?, 123) dtype=float32>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_in = Lambda(lambda ou: sum([ou[0], ou[1]]))([o, u])\n",
    "print(a_in.shape)\n",
    "#a_in = Reshape(target_shape=(n_hidden,))(a_in)\n",
    "op = Reshape(target_shape=(n_hidden,))(a_in)\n",
    "op = Dense(vocab_size, activation='softmax')(op)\n",
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'input_75:0' shape=(?, 88, 8) dtype=float32>,\n",
       " <tf.Tensor 'input_76:0' shape=(?, 5) dtype=float32>,\n",
       " <tf.Tensor 'dense_25/Softmax:0' shape=(?, 123) dtype=float32>)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_in, query_input, op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parms = {'verbose': 2, 'callbacks': [TQDMNotebookCallback(leave_inner=False)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "babi_memmn = Model([mem_in, query_input], op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "babi_memmn.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "4s - loss: 1.7233 - acc: 0.2695 - val_loss: 1.5403 - val_acc: 0.3450\n",
      "Epoch 2/5\n",
      "3s - loss: 1.5053 - acc: 0.3653 - val_loss: 1.4843 - val_acc: 0.3710\n",
      "Epoch 3/5\n",
      "4s - loss: 1.4913 - acc: 0.3746 - val_loss: 1.4921 - val_acc: 0.3640\n",
      "Epoch 4/5\n",
      "3s - loss: 1.4874 - acc: 0.3807 - val_loss: 1.5184 - val_acc: 0.3670\n",
      "Epoch 5/5\n",
      "3s - loss: 1.4844 - acc: 0.3814 - val_loss: 1.5361 - val_acc: 0.3550\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179cd36e358>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(babi_memmn.optimizer.lr, 1e-2)\n",
    "babi_memmn.fit([m_train, q_train], a_train, **parms, batch_size=32, epochs=5,\n",
    "               validation_data=([m_test, q_test], a_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2 hop network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 123, 30)\n",
      "<class 'keras.layers.embeddings.Embedding'>\n",
      "(?, 88, 30)\n",
      "(?, 5, 30)\n",
      "(?, 30)\n"
     ]
    }
   ],
   "source": [
    "first_embedding = TimeDistributed(Embedding(vocab_size,output_dim=n_hidden))\n",
    "\n",
    "\n",
    "mem_input = Input(shape=(max_num_memories, max_memory_len))\n",
    "\n",
    "query_input = Input(shape=(max_ques_len,))\n",
    "\n",
    "x = first_embedding(mem_input)\n",
    "print(np.array(first_embedding.get_weights()).shape)\n",
    "\n",
    "print(type(first_embedding.layer))\n",
    "m_i = Lambda(lambda xx: K.sum(xx, 2))(x)\n",
    "\n",
    "\n",
    "print(m_i.shape)\n",
    "u = first_embedding.layer(query_input)\n",
    "print(u.shape)\n",
    "u = Lambda(lambda x : K.sum(x, 1))(u)\n",
    "print(u.shape)\n",
    "\n",
    "h = Dense(n_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hop(m_i, u):\n",
    "    x = TimeDistributed(Embedding(vocab_size, n_hidden))(mem_input)\n",
    "    c_i = Lambda(lambda xx: K.sum(xx, 2))(x)\n",
    "    u = Reshape((1, n_hidden))(u)\n",
    "    p = dot([m_i, u], axes=2)\n",
    "    p = Reshape((max_num_memories,))(p)\n",
    "    p = Activation(activation='softmax')(p)\n",
    "    p = Reshape((max_num_memories,1))(p)\n",
    "    o = dot([c_i, p], axes=1)\n",
    "    #o = Reshape(target_shape=(1,n_hidden))(o)\n",
    "    o = Reshape(target_shape=(n_hidden,))(o)\n",
    "    u = Reshape(target_shape=(n_hidden,))(u)\n",
    "    u = h(u)\n",
    "    u2 = Lambda(lambda ou: sum([ou[0], ou[1]]))([o, u])\n",
    "    return u2, c_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u2, c1 = hop(m_i, u)\n",
    "u3, _ = hop(c1, u2)\n",
    "u3 = Reshape((n_hidden,))(u3)\n",
    "op = Dense(vocab_size, activation='softmax')(u3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "babi_memmn2 = Model([mem_input, query_input], op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/8\n",
      "6s - loss: 1.9472 - acc: 0.1689 - val_loss: 1.7751 - val_acc: 0.2580\n",
      "Epoch 2/8\n",
      "5s - loss: 1.7384 - acc: 0.2600 - val_loss: 1.6802 - val_acc: 0.3400\n",
      "Epoch 3/8\n",
      "5s - loss: 1.6227 - acc: 0.3420 - val_loss: 1.5845 - val_acc: 0.3490\n",
      "Epoch 4/8\n",
      "5s - loss: 1.5229 - acc: 0.3750 - val_loss: 1.5333 - val_acc: 0.3690\n",
      "Epoch 5/8\n",
      "5s - loss: 1.4866 - acc: 0.3838 - val_loss: 1.4886 - val_acc: 0.3770\n",
      "Epoch 6/8\n",
      "5s - loss: 1.4694 - acc: 0.3860 - val_loss: 1.4874 - val_acc: 0.3800\n",
      "Epoch 7/8\n",
      "5s - loss: 1.4542 - acc: 0.3915 - val_loss: 1.5079 - val_acc: 0.3750\n",
      "Epoch 8/8\n",
      "5s - loss: 1.4472 - acc: 0.3985 - val_loss: 1.4884 - val_acc: 0.3670\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179b10b7eb8>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babi_memmn2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "K.set_value(babi_memmn.optimizer.lr, 5e-3)\n",
    "babi_memmn2.fit([m_train, q_train], a_train, **parms, batch_size=32, epochs=8,\n",
    "               validation_data=([m_test, q_test], a_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d4cdaf45b6a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbabi_memmn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmemories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
